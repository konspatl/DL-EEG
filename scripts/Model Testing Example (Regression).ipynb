{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4f66ce",
   "metadata": {},
   "source": [
    "# Model Testing for State-based EEG Decoding Tasks\n",
    "\n",
    "Author: Konstantinos Patlatzoglou\n",
    "\n",
    "A simple python pipeline for:\n",
    "1) Loading a deep learning model for EEG decoding (Tensorflow/Keras support)\n",
    "\n",
    "2) Testing a model based on several selected EEG dataset parameters (multi-study integration support)\n",
    "\n",
    "\n",
    "## Packages required:\n",
    "* numpy \n",
    "* pathlib \n",
    "* natsort \n",
    "* pandas \n",
    "* h5py\n",
    "* scikit-learn\n",
    "* tensorflow>=2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b54b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pathlib\n",
    "!pip install natsort\n",
    "!pip install pandas\n",
    "!pip install h5py\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow==2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent / 'DL-EEG')) # Add utils package\n",
    "\n",
    "from utils import utils\n",
    "from utils import EEG\n",
    "from utils import NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa45d3",
   "metadata": {},
   "source": [
    "# Model Testing Parameters\n",
    "\n",
    "This pipeline has been developed to be compatible with the EEG dataset specifications found in *'export_dataset.py'*. \n",
    "\n",
    "Briefly, a number of EEG datasets can be selected based on the *EEG_DATASET* parameters and the *'EEG_DATASET_PARAMETERS.json'* specification file of the corresponding dataset directory (+ *subject_eeg_data.npy*, *subject_info.json*), which includes the available *subjects*, *states*, and *export* variables that can be incorporated as training/testing targets.\n",
    "\n",
    "**Dataset Directory:**\n",
    "\n",
    "*EEG_DATASET_PARAMETERS.json*:\n",
    "* *EEG_DATASET*:\n",
    " * *Study* - study name\n",
    " * *Subjects* - list of subjects\n",
    " * *States* - list of states\n",
    " * *Export* - list of export keys\n",
    " * *Other* - dict (Optional)\n",
    "* *EEG_PARAMETERS*:\n",
    " * *Channels* - name of channel selection\n",
    " * *Sfreq* - sampling frequency (Hz)\n",
    " * *Epoch Size* - epoch window size (sec)\n",
    " * *Reference* - reference montage name\n",
    " * *Topomap* - topomap representation (boolean) (Optional)\n",
    " * *...* (Optional)\n",
    "\n",
    "*subject_eeg_data.npy* - Epoched EEG Data (ndarray)\n",
    "\n",
    "*subject_info.json*:\n",
    " * *States* - list of states\n",
    " * *Channels* - list of channel names\n",
    " * *Export* - dict of export values per key and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR_NAME = 'Model Training (Regression)'  # Name of Model Training Directory\n",
    "RESULTS_DIR_NAME = 'Model Testing (Regression)'  # Name of Model Testing Directory\n",
    "\n",
    "\n",
    "NO_OF_DATASETS = 1\n",
    "\n",
    "EEG_DATASET_1 = {'Study': 'Cambridge Anesthesia',\n",
    "                 'Subjects': ['S3'],\n",
    "                 'States': ['Wakefulness', 'Sedation'],\n",
    "                 'Targets': ['Drug Levels'], # '1-hot' (Classifcation), list [target1, target2, ] (Regression)\n",
    "                 'Target Values': 'Read_from_info_file', # None, 'Read_from_info_file', list [[], [], ...]\n",
    "                 }\n",
    "\n",
    "SEPARATE_DATASET_RESULTS = False  # Export Results in Separate Directories for each Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f670e",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "First, we load the model found in the given directory name (*MODEL_DIR_NAME*). This directory includes the specified model training parameters in the files *'EEG_DATASET_PARAMETERS.json'*, *'MODEL_PARAMETERS.json'*, *'MODEL_INFO.json'* and *'CLASSES.json'* (Optional).\n",
    "\n",
    "**Model Training Directory:**\n",
    "\n",
    "*EEG_DATASET_PARAMETERS.json*:\n",
    "* *EEG_DATASET*:\n",
    " * *Study* - study name\n",
    " * *Subjects* - list of subjects\n",
    " * *States* - list of states\n",
    " * *Targets* - str ('1-hot') or list of targets\n",
    " * *Target Values* - str ('Read_from_info_file'), list of targets, or None\n",
    "* *EEG_PARAMETERS*\n",
    "\n",
    "*MODEL_PARAMETERS.json*:\n",
    " * *Model* - model name\n",
    " * *EEG Normalization* - str of epoch normalization method\n",
    " * *Sample Weights* - training instance weights (boolean)\n",
    " * *Target Weights* - training target weights (boolean)\n",
    " * *Shuffle Samples* - (boolean)\n",
    " * *Optimizer* - optimizer name (tensorflow arg)\n",
    " * *Learning Rate* - learning rate (tensorflow arg)\n",
    " * *Loss* - name of loss function (tensorflow arg)\n",
    " * *Metrics* - list of metrics (tensorflow arg)\n",
    " * *Batch Size* - training batch size (tensorflow arg)\n",
    " * *Epochs* - number of training epochs (tensorflow arg)\n",
    "\n",
    "*MODEL_INFO.json*:\n",
    "* *Input shape* - EEG data input shape\n",
    "* *Sfreq* - EEG sampling frequency (Hz)\n",
    "* *Output shape* - target output shape\n",
    "* *Targets* - str ('1-hot') or list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path.cwd()\n",
    "\n",
    "model_path = current_path.parent / 'results' / MODEL_DIR_NAME\n",
    "\n",
    "# Load MODEL_PARAMETERS and MODEL_INFO Structures\n",
    "MODEL_PARAMETERS = json.load(open(str(model_path / 'MODEL_PARAMETERS.json')))\n",
    "model_info = json.load(open(str(model_path / 'MODEL_INFO.json')))\n",
    "\n",
    "CLASSES = None\n",
    "if model_info['Targets'] == '1-hot':\n",
    "    CLASSES = json.load(open(str(model_path / 'CLASSES.json')))\n",
    "\n",
    "# Load Model\n",
    "model = NN.get_model(str(model_path / 'Model.tf'))\n",
    "model.summary()\n",
    "\n",
    "model_memory_usage = NN.get_model_memory_usage(model, MODEL_PARAMETERS['Batch Size'])\n",
    "print('Model Memory Usage:' + str(model_memory_usage) + ' GB')\n",
    "print()\n",
    "\n",
    "MODEL_CHECKPOINT = False\n",
    "checkpoint_models = None\n",
    "training_history = None\n",
    "\n",
    "# Check for Model Checkpoint (Load Epoch Models + Training history)\n",
    "if os.path.exists(model_path / 'Model Checkpoint'):\n",
    "    MODEL_CHECKPOINT = True\n",
    "    checkpoint_models = NN.get_checkpoint_models(model_path / 'Model Checkpoint')\n",
    "    training_history = json.load(open(str(model_path / 'Model Checkpoint' / 'training_history.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b9a06",
   "metadata": {},
   "source": [
    "# Import EEG Datasets\n",
    "\n",
    "We import the selected EEG datasets and concatenate them into a single *eeg_dataset* dictionary. Datasets are integrated after checking consistency across the EEG sampling frequency, channel names, reference montage, epoch size and targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ed092",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = current_path.parent / 'data'\n",
    "\n",
    "eeg_datasets = []\n",
    "for i in range(NO_OF_DATASETS): # For each specified Dataset\n",
    "\n",
    "    EEG_DATASET = globals()['EEG_DATASET_' + str(i+1)]\n",
    "    dataset_path = EEG.find_dataset_path(datasets_path, EEG_DATASET)\n",
    "\n",
    "    if dataset_path is None:\n",
    "        print('No dataset with the given parameters found')\n",
    "        exit(1)\n",
    "\n",
    "    # Get the Dataset from the corresponding directory\n",
    "    # Dict ('EEG Dataset Parameters', 'Subjects', 'EEG Data', 'Info')\n",
    "    raw_eeg_dataset = EEG.get_dataset(dataset_path)\n",
    "\n",
    "    # Select the Data specified in EEG_DATASET with respect to Subjects, States and Targets\n",
    "    # Dict ('EEG Dataset Parameters', 'Subjects', 'Dataset ID', 'EEG Data', 'States', 'Channels', 'Targets',\n",
    "    #       'Target Values')\n",
    "    eeg_dataset = EEG.select_data_from_dataset(raw_eeg_dataset, EEG_DATASET, id=i)\n",
    "    eeg_datasets.append(eeg_dataset)\n",
    "\n",
    "# Check Datasets Consistency (Sampling Frequency, Reference Montage, Channel names, Epoch Size, Targets)\n",
    "if not EEG.check_datasets_consistency(eeg_datasets):\n",
    "    print('Datasets cannot be integrated')\n",
    "    exit(2)\n",
    "\n",
    "# Concatenate All Datasets\n",
    "eeg_dataset = EEG.concatenate_datasets(eeg_datasets)\n",
    "del eeg_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e956e",
   "metadata": {},
   "source": [
    "*eeg_dataset*:\n",
    "* *eeg_dataset_parameters* (list): List of EEG_DATASET_PARAMETERS for each dataset\n",
    "* *subjects* (list): list of subjects (subject,)\n",
    "* *dataset_id* (list): list of dataset ids (subject,)\n",
    "* *eeg_data_list* (list): list of eeg data (subject,) (state,) (epoch, channel, sample)\n",
    "* *states_list* (list): list of states (subject,) (state,)\n",
    "* *channels_list* (list): list of channel names (subject,)\n",
    "* *targets* (str or list): target name or list of target names\n",
    "* *targets_list* (list or None): list of target values (subject,) (state,) (epoch, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset_parameters = eeg_dataset['EEG Dataset Parameters']\n",
    "subjects = eeg_dataset['Subjects']\n",
    "dataset_id = eeg_dataset['Dataset ID']\n",
    "eeg_data_list = eeg_dataset['EEG Data']\n",
    "states_list = eeg_dataset['States']\n",
    "channels_list = eeg_dataset['Channels']\n",
    "targets = eeg_dataset['Targets']\n",
    "targets_list = eeg_dataset['Target Values']\n",
    "\n",
    "del eeg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1fa75",
   "metadata": {},
   "source": [
    "# EEG Pre-Processing\n",
    "\n",
    "The EEG data need to be pre-processed before we feed them into the deep learning networks. This process includes the *normalization* of the epoch instances (as EEG data are typically in Î¼V) and *reshaping* the dimensions, which is a requirement for DL-based EEG models (e.g. with respect to channel information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Topomap Model Compatibility\n",
    "if MODEL_PARAMETERS['Model'] == 'cNN_topomap':\n",
    "    if not EEG.check_EEG_model_compatibility(eeg_data_list, 'cNN_topomap'):\n",
    "        print('EEG data shape is incompatible with selected Model')\n",
    "        exit(3)\n",
    "\n",
    "# Perform EEG Normalization (e.g. epoch-wise Standardization)\n",
    "eeg_data_list = EEG.normalize_EEG_data_list(eeg_data_list, MODEL_PARAMETERS['EEG Normalization'])\n",
    "\n",
    "# Reshape EEG data according to Model + Add Kernel Dimension\n",
    "# e.g. If Toy Model (1D), reshape EEG data into (epoch, sample)\n",
    "# e.g. If cNN_3D model (3D), reshape EEG data into (epoch, channel, channel, sample, 1)\n",
    "eeg_data_list = EEG.reshape_EEG_data_list(eeg_data_list, channels_list, MODEL_PARAMETERS['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597d468",
   "metadata": {},
   "source": [
    "# EEG Data / Model Consistency Check\n",
    "\n",
    "We can check the consistency of our EEG data with the selected model, with respect to *input shape*, *output shape*, *EEG sampling frequency* and *learning algorithm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Info\n",
    "input_shape = eeg_data_list[0][0].shape[1:]  # Model Input Shape\n",
    "sfreq = eeg_dataset_parameters[0]['EEG_PARAMETERS']['Sfreq']  # EEG Sampling Frequency\n",
    "\n",
    "if targets == '1-hot':  # Classification\n",
    "    classification = True\n",
    "else:  # Regression\n",
    "    classification = False\n",
    "\n",
    "# If Target Values\n",
    "if targets_list is None:\n",
    "    output_shape = tuple(model_info['Output shape'])\n",
    "else:\n",
    "    output_shape = targets_list[0][0].shape[1:]  # Model Output Shape\n",
    "\n",
    "# Check Model Consistency\n",
    "if input_shape != tuple(model_info['Input shape']) \\\n",
    "    or output_shape != tuple(model_info['Output shape']) \\\n",
    "    or sfreq != model_info['Sfreq'] \\\n",
    "    or targets != model_info['Targets']:\n",
    "\n",
    "    print('EEG Data are inconsistent with selected model!')\n",
    "    exit(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b79a2e",
   "metadata": {},
   "source": [
    "# Create Results Directory\n",
    "\n",
    "A results directory is created to store the testing EEG dataset results, along with the specified training and testing parameters (*EEG_DATASET_PARAMETERS*, *MODEL_PARAMETERS*, *MODEL_INFO*, *CLASSES* (Optional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4543b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = current_path.parent / 'results' / RESULTS_DIR_NAME\n",
    "utils.create_directory(result_path)\n",
    "\n",
    "# For each Dataset, save EEG_DATASET_PARAMETERS (EEG_DATASET + EEG_PARAMETERS)\n",
    "for i in range(NO_OF_DATASETS):\n",
    "\n",
    "    EEG_DATASET = globals()['EEG_DATASET_' + str(i + 1)]\n",
    "    if 'Other' in eeg_dataset_parameters[i]['EEG_DATASET']:  # Concatenate 'Other' in EEG_DATASET\n",
    "        EEG_DATASET['Other'] = eeg_dataset_parameters[i]['EEG_DATASET']['Other']\n",
    "    EEG_PARAMETERS = eeg_dataset_parameters[i]['EEG_PARAMETERS']\n",
    "\n",
    "    EEG_DATASET_PARAMETERS = {'EEG_DATASET': EEG_DATASET, 'EEG_PARAMETERS':EEG_PARAMETERS}\n",
    "    json.dump(EEG_DATASET_PARAMETERS, open(str(result_path / ('EEG_DATASET_PARAMETERS_' + str(i + 1) + '.json')),\n",
    "                                           'w'), indent=4)\n",
    "\n",
    "# Save MODEL_PARAMETERS\n",
    "json.dump(MODEL_PARAMETERS, open(str(result_path / 'MODEL_PARAMETERS.json'), 'w'), indent=4)\n",
    "\n",
    "# Save MODEL_INFO\n",
    "json.dump(model_info, open(str(result_path / 'MODEL_INFO.json'), 'w'), indent=4)\n",
    "\n",
    "# If Classification, Save CLASSSES\n",
    "if model_info['Targets'] == '1-hot':\n",
    "    json.dump(CLASSES, open(str(result_path / 'CLASSES.json'), 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618141d",
   "metadata": {},
   "source": [
    "# Model Testing and Results Export\n",
    "\n",
    "For each subject in our test dataset, we concatenate the states and create our input and output (if available) tensors (*Xte_t*, (*Yte_t*)). The model predictions are then calculated for the given subject.\n",
    "\n",
    "If *'Target Values'* are provided in EEG_DATASET parameters, a subject score (*loss/metric*) is evaluated and stored in the results.\n",
    "\n",
    "If *MODEL_CHECKPOINT* is True, a score is calculated for each training epoch of the respective model.\n",
    "\n",
    "Finally, we can save the subject predictions and other subject info (*'States'*, *'Channels'*, *'Target Values'*, *'Score'*, *'History'*) in our results directory for further analysis (*'subject_predictions.npy'*, *'subject_info.json'*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Subjects' + str(subjects))\n",
    "\n",
    "for test_index, test_subject in enumerate(subjects):\n",
    "\n",
    "    print('Test Subject: ' + test_subject)\n",
    "\n",
    "    # Concatenate States\n",
    "    Xte, Yte, _ = utils.concatenate_data(eeg_data_list, targets_list=targets_list)\n",
    "\n",
    "    # Testing Data\n",
    "    Xte_t, Yte_t = utils.get_tensor_maps(Xte, Y=Yte, classification=classification)\n",
    "\n",
    "    # Model Prediction\n",
    "    Ypred = model.predict(Xte_t, batch_size=MODEL_PARAMETERS['Batch Size'])\n",
    "    if isinstance(Ypred, list): # If Multiple Regression Targets\n",
    "        Ypred = utils.merge_targets(Ypred)\n",
    "\n",
    "    score = None\n",
    "    history = None\n",
    "\n",
    "    # Model Evalution (Score)\n",
    "    if Yte_t is not None:  # If Target Values\n",
    "        score = model.evaluate(Xte_t, Yte_t, batch_size=MODEL_PARAMETERS['Batch Size'], verbose=0)\n",
    "        score = dict(zip(model.metrics_names, score))\n",
    "\n",
    "        # Model Checkpoint (History)\n",
    "        if MODEL_CHECKPOINT:\n",
    "            metrics_names = [('val_' + metric_name) for metric_name in model.metrics_names]\n",
    "            history = []\n",
    "\n",
    "            for epoch in range(MODEL_PARAMETERS['Epochs']): # For each Epoch\n",
    "                epoch_score = checkpoint_models[epoch].evaluate(Xte_t, Yte_t,\n",
    "                                                                batch_size=MODEL_PARAMETERS['Batch Size'],\n",
    "                                                                verbose=0)\n",
    "                history.append(epoch_score)\n",
    "            history = [list(np.array(history)[:, metric]) for metric in range(len(model.metrics_names))]\n",
    "            history = dict(zip(metrics_names, history))\n",
    "            history.update(training_history) # Add Training History\n",
    "\n",
    "    # --------------------- Export Subject Results ------------------------------\n",
    "    # Select Subject Export Path\n",
    "    if SEPARATE_DATASET_RESULTS:\n",
    "        dataset_export_path = result_path / ('EEG DATASET ' + str(dataset_id[test_index]+1))\n",
    "    else:\n",
    "        dataset_export_path = result_path / 'EEG DATASET'\n",
    "\n",
    "    if not dataset_export_path.exists():\n",
    "        utils.create_directory(dataset_export_path)\n",
    "\n",
    "\n",
    "    # Calculate per-state Predictions and Target Values\n",
    "    state_epochs = [state.shape[0] for state in eeg_data_list[test_index]]\n",
    "    predictions = utils.reshape_predictions(Ypred, state_epochs)\n",
    "    target_values = None\n",
    "\n",
    "    if targets_list is not None: # If Target Values\n",
    "        target_values = [list(target[0]) for target in targets_list[test_index]]\n",
    "\n",
    "    # Subject Info\n",
    "    subject_info = {'States': list(states_list[test_index]),\n",
    "                    'Channels': list(channels_list[test_index]),\n",
    "                    'Target Values': target_values,\n",
    "                    'Score': score,\n",
    "                    'History': history\n",
    "                    }\n",
    "\n",
    "    # Export Predictions as numpy array\n",
    "    np.save(str(dataset_export_path / (test_subject + '_predictions.npy')), predictions, allow_pickle=True)\n",
    "    # Export Subject Info as a json file\n",
    "    json.dump(subject_info, open(str(dataset_export_path / (test_subject + '_info.json')), 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ccafa",
   "metadata": {},
   "source": [
    "# Predictions Visualization and Other Metrics\n",
    "\n",
    "We can visualize the predictions of the model and other available metrics (e.g. *loss/metric history*, *confusion matrix*) to get a better sense of our model's behavior and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import output\n",
    "\n",
    "subject = 'S3'\n",
    "predictions = predictions = np.load(str(dataset_export_path / (subject + '_predictions.npy')), allow_pickle=True)\n",
    "subject_info = json.load(open(str(dataset_export_path / (subject + '_info.json'))))\n",
    "\n",
    "# Plot Predictions\n",
    "fig = output.plot_predictions(subject, predictions, subject_info['States'], model_info['Targets'], \n",
    "                              target_values=subject_info['Target Values'], CLASSES=CLASSES, \n",
    "                              states_colors=['red', 'blue'], class_colors=['red', 'blue'])\n",
    "\n",
    "fig.savefig(str(dataset_export_path / (subject + '_predictions.png')))\n",
    "\n",
    "# Plot History\n",
    "if subject_info['History'] is not None:\n",
    "    fig = output.plot_history(subject, subject_info['History'], loss=MODEL_PARAMETERS['Loss'], \n",
    "                              metrics=MODEL_PARAMETERS['Metrics'])\n",
    "    \n",
    "    fig.savefig(str(dataset_export_path / (subject + '_history.png')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d63136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
